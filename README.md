# Проверки организаций — Автоматизированный парсер и веб-интерфейс

## Описание

Этот проект автоматически собирает данные о проверках организаций с сайта Госуслуг, сохраняет их в базу данных SQLite и предоставляет удобный веб-интерфейс для просмотра с поиском и пагинацией.

**Особенности:**
- Автоматическая обработка ошибок 504 (Gateway Timeout) и других временных ошибок
- Повторные попытки с экспоненциальной задержкой
- Продолжение работы даже при ошибках на отдельных страницах
- Надежная обработка сетевых сбоев

---

## Быстрый старт в Docker

1. **Соберите и запустите контейнер:**
   ```sh
   docker-compose up --build
   ```
2. Откройте сайт: [http://localhost:5000](http://localhost:5000)
3. Данные будут автоматически обновляться каждый час (cron внутри контейнера).

---

## Запуск без Docker (локально)

1. Установите Python 3.11+ и зависимости:
   ```sh
   pip install -r requirements.txt
   python -m playwright install --with-deps
   ```
2. Запустите парсер и загрузку данных:
   ```sh
   python parser.py
   ```
3. Запустите сервер:
   ```sh
   python server.py
   ```
4. Откройте сайт: [http://localhost:5000](http://localhost:5000)

---

## Структура проекта
- `parser.py` — основной запуск парсинга (Playwright), передаёт заголовки в парсер API.
- `parser_v2.py` — парсер API Госуслуг, сразу загружает данные в БД.
- `load_to_sqlite.py` — функции для загрузки данных в SQLite (без работы с JSON).
- `server.py` — Flask-сервер для просмотра данных.
- `templates/index.html` — внешний вид сайта (Bootstrap, карточки).
- `Dockerfile`, `docker-compose.yml` — для автоматизации и запуска в Docker.
- `requirements.txt` — зависимости Python.

---

## Обработка ошибок

### Автоматические повторные попытки

Парсер автоматически обрабатывает следующие ошибки с повторными попытками:
- **504 Gateway Timeout** — таймаут сервера
- **408 Request Timeout** — таймаут запроса
- **429 Too Many Requests** — превышение лимита запросов
- **500 Internal Server Error** — внутренняя ошибка сервера
- **502 Bad Gateway** — ошибка шлюза
- **503 Service Unavailable** — сервис недоступен
- **520-524** — ошибки Cloudflare и других CDN

### Стратегия повторных попыток

- **Максимум 5 попыток** для каждого запроса
- **Экспоненциальная задержка** с джиттером: 1с, 2с, 4с, 8с, 16с
- **Таймаут запроса** 30 секунд
- **Продолжение работы** даже при ошибках на отдельных страницах

### Логирование

Все попытки и ошибки логируются с подробной информацией:
```
[INFO] Попытка 1/5 для страницы 1
[WARNING] Получен статус 504. Повторная попытка через 1.2 секунд...
[INFO] Попытка 2/5 для страницы 1
[INFO] POST https://dom.gosuslugi.ru/... — статус: 200
```

---

## Диагностика и настройка cron

- Cron-задача для автоматического обновления данных теперь прописывается вручную или через Dockerfile.
- Пример строки для `/etc/cron.d/update_data`:
  ```
  0 * * * * root cd /app && /usr/local/bin/python -u parser.py && /usr/local/bin/python -u load_to_sqlite.py >> /var/log/cron.log 2>&1
  ```
- Для диагностики работы cron смотрите логи:
  ```sh
  tail /var/log/cron.log
  ```
- Для теста можно временно добавить строку:
  ```
  * * * * * root echo "cron test $(date)" >> /var/log/cron.log 2>&1
  ```
  Если строки появляются каждую минуту — cron работает корректно.

---

## Проблемы с форматом файлов (Windows)

- Есть вероятность, что при скачивании проект на ПК (Windows) cron-файлы будут сохранены в формате CRLF (Windows)
- Вам нужно перевести их в LF (Unix-формат)
- Для этого используйте PowerShell:
     ```powershell
     (Get-Content /etc/cron.d/update_data) | ForEach-Object { $_ -replace "\r", "" } | Set-Content /etc/cron.d/update_data
     ```
- Готово, собираем контейнер